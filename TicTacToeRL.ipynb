{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mesh = 3\n",
    "nb_line = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruhokondo/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/ruhokondo/Programming/anaconda3/envs/dl35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 16)          448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3, 3, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 145       \n",
      "=================================================================\n",
      "Total params: 5,425\n",
      "Trainable params: 5,329\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "state = h = Input((nb_mesh,nb_mesh,3))\n",
    "\n",
    "if True:\n",
    "    h = Conv2D(16, (3,3), padding='same')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Conv2D(16, (3,3), padding='same')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Conv2D(16, (3,3), padding='same')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "else:\n",
    "    h = Dense(16, activation='relu')(h)\n",
    "    h = Dense(16, activation='relu')(h)\n",
    "\n",
    "h = Flatten()(h)\n",
    "value = Dense(1, activation='tanh')(h)\n",
    "\n",
    "value_function = Model(state, value)\n",
    "optimizer = Adam(lr=1e-4)\n",
    "value_function.compile(loss='mse', optimizer=optimizer)\n",
    "value_function.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permitted_actions(state):\n",
    "    '''\n",
    "    ○および×が置かれていない座標インデックスを返す。\n",
    "    '''\n",
    "    return np.where(state[:,:,0]+state[:,:,1]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def transition(current_state, action):\n",
    "    '''\n",
    "    action は ○ もしくは × を置く state のインデックス。\n",
    "    3チャンネル目が手番を表しているので、遷移後は手番を入れ替える。\n",
    "    '''\n",
    "    next_state = copy.deepcopy(current_state)\n",
    "    if current_state[:,:,-1][0,0]==0: # ○の手番の場合\n",
    "        next_state[action+(0,)] = 1\n",
    "        next_state[:,:,-1] = np.ones((nb_mesh,nb_mesh))\n",
    "    else: # ×の手番の場合\n",
    "        next_state[action+(1,)] = 1\n",
    "        next_state[:,:,-1] = np.zeros((nb_mesh,nb_mesh))\n",
    "    return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(state):\n",
    "    a0,a1 = get_permitted_actions(state)\n",
    "    max_value = -2e100\n",
    "    for action in zip(a0,a1):\n",
    "        next_state = transition(state, action)\n",
    "\n",
    "        if judge_game(next_state) is not None:\n",
    "            value = 1.\n",
    "        else:\n",
    "            value = value_function.predict(np.expand_dims(next_state,0)).squeeze()\n",
    "\n",
    "        if value>max_value:\n",
    "            best_action = action\n",
    "            max_value = value\n",
    "            \n",
    "    return best_action, max_value\n",
    "\n",
    "\n",
    "def search_best_action(current_state, value_function):\n",
    "    '''\n",
    "    行動空間が狭いので全探索する。\n",
    "    '''\n",
    "    a0,a1 = get_permitted_actions(current_state)\n",
    "    max_value = -1e100\n",
    "    \n",
    "    # 自分の取り得る全ての行動を探索する\n",
    "    if len(a0)>1:\n",
    "        try:\n",
    "            for action in zip(a0,a1):\n",
    "\n",
    "                # 行動を取って1つ状態を進める。相手の手番になる。\n",
    "                next_state = transition(current_state, action)\n",
    "\n",
    "                # 次の自分の一手で勝敗が決していなかった場合のみ、相手の手筋を読む（全探索）。\n",
    "                if judge_game(next_state) is None:\n",
    "\n",
    "                    # 相手の取り得る全ての行動を調べ、最も取りそうな行動を調べる。\n",
    "                    enemy_action, enemy_value = get_best_action(next_state)\n",
    "\n",
    "                    if False:\n",
    "                        # 次の自分の手番での最大価値を探索\n",
    "                        next_next_state = transition(next_state, enemy_action)\n",
    "                        second_action, second_value = get_best_action(next_next_state)\n",
    "                        if second_value>max_value:\n",
    "                            best_action = action\n",
    "                            max_value = second_value\n",
    "\n",
    "                    else:\n",
    "                        # 相手が獲得し得る最大の盤面価値をv∈[-1,1]としたとき、自分の盤面価値を-v∈[-1,1]と想定する\n",
    "                        if -enemy_value>max_value:\n",
    "                            best_action = action\n",
    "                            max_value = -enemy_value\n",
    "\n",
    "                # 次の自分の一手で自分が勝ってしまったら探索をやめる。\n",
    "                else:\n",
    "                    max_value = 1.\n",
    "                    best_action = action\n",
    "                    raise Exception\n",
    "\n",
    "        except Exception as e:\n",
    "    #        print('=== エラー内容 ===')\n",
    "    #        print('type:' + str(type(e)))\n",
    "    #        print('args:' + str(e.args))\n",
    "    #        print('message:' + e.message)\n",
    "    #        print('e自身:' + str(e))\n",
    "            pass\n",
    "                    \n",
    "    else:\n",
    "        max_value = value_function.predict(np.expand_dims(current_state,0)).squeeze()\n",
    "        best_action = (a0,a1)\n",
    "        \n",
    "    return max_value, best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_game(state):\n",
    "    winner = None\n",
    "    checked = np.zeros(state.shape[:2])\n",
    "    \n",
    "    try:\n",
    "        for i in range(state.shape[0]):\n",
    "            for j in range(state.shape[1]):\n",
    "                s = state[i,j,:2].argmax(-1)\n",
    "\n",
    "                # 右側をチェック\n",
    "                count = 0\n",
    "                for jj in range(j,min(j+nb_line,state.shape[1])):\n",
    "                    if state[i,jj,s]==1:\n",
    "                        count += 1\n",
    "                    if count==nb_line:\n",
    "                        winner = s\n",
    "                        raise Exception\n",
    "                    \n",
    "                # 下側をチェック\n",
    "                count = 0\n",
    "                for ii in range(i,min(i+nb_line,state.shape[0])):\n",
    "                    if state[ii,j,s]==1:\n",
    "                        count += 1\n",
    "                    if count==nb_line:\n",
    "                        winner = s\n",
    "                        raise Exception\n",
    "                        \n",
    "                # 右下をチェック\n",
    "                count = 0\n",
    "                for ii,jj in zip(range(i,min(i+nb_line,state.shape[0])),range(j,min(j+nb_line,state.shape[1]))):\n",
    "                    if state[ii,jj,s]==1:\n",
    "                        count += 1\n",
    "                    if count==nb_line:\n",
    "                        winner = s\n",
    "                        raise Exception\n",
    "                        \n",
    "                # 左下をチェック\n",
    "                count = 0\n",
    "                for ii,jj in zip(range(i,max(i-nb_line,0)-1,-1),range(j,min(j+nb_line,state.shape[1]))):\n",
    "                    if state[ii,jj,s]==1:\n",
    "                        count += 1\n",
    "                    if count==nb_line:\n",
    "                        winner = s\n",
    "                        raise Exception\n",
    "                        \n",
    "    except Exception as e:\n",
    "#        print('=== エラー内容 ===')\n",
    "#        print('type:' + str(type(e)))\n",
    "#        print('args:' + str(e.args))\n",
    "#        print('message:' + e.message)\n",
    "#        print('e自身:' + str(e))\n",
    "        pass\n",
    "    \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discount = 0.99\n",
    "discount = 1.\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state_2(state):\n",
    "    board = np.zeros((nb_mesh,nb_mesh))\n",
    "    board += state[:,:,0]\n",
    "    board -= state[:,:,1]\n",
    "    plt.imshow(board, 'RdBu_r')\n",
    "    plt.title(value_function.predict(np.expand_dims(state,0)).squeeze())\n",
    "    plt.clim(-1,1)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0, nb_mesh, 1))\n",
    "    ax.set_yticks(np.arange(0, nb_mesh, 1))\n",
    "    ax.set_xticks(np.arange(-.5, nb_mesh+.5, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, nb_mesh+.5, 1), minor=True)\n",
    "    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 382/1000 [01:13<01:58,  5.21it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-aabe25c8d5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# 状態価値が最も高くなる行動と、その行動を取った時の遷移後の状態価値(報酬)を計算する。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_best_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# 状態価値が最も高くなる行動を選択する。ただし、確率εでランダムな行動を取る。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ad07d0139c08>\u001b[0m in \u001b[0;36msearch_best_action\u001b[0;34m(current_state, value_function)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;31m# 相手の取り得る全ての行動を調べ、最も取りそうな行動を調べる。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0menemy_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menemy_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ad07d0139c08>\u001b[0m in \u001b[0;36mget_best_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1842\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/anaconda3/envs/dl35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for nb_episode in tqdm(range(1000)):\n",
    "    \n",
    "    # 状態の初期化\n",
    "    current_state = np.zeros((nb_mesh,nb_mesh,3))\n",
    "    current_state[:,:,-1] = np.random.randint(0,2) # ランダムに先手を決める。\n",
    "\n",
    "    winner = None\n",
    "    surrender = False\n",
    "    try:\n",
    "        for nb_move in range(nb_mesh*nb_mesh):\n",
    "\n",
    "            # 盤面の表示\n",
    "#            show_state_2(current_state)\n",
    "#            plt.show()\n",
    "\n",
    "            # 現在の指し手\n",
    "            current_move = current_state[0,0,-1].astype(np.int32)\n",
    "\n",
    "            # 状態価値が最も高くなる行動と、その行動を取った時の遷移後の状態価値(報酬)を計算する。\n",
    "            reward, best_action = search_best_action(current_state, value_function)\n",
    "\n",
    "            # 状態価値が最も高くなる行動を選択する。ただし、確率εでランダムな行動を取る。\n",
    "            if np.random.random(1)<epsilon:\n",
    "                acceptable_action = get_permitted_actions(current_state)\n",
    "                random_idx = np.random.randint(0,len(acceptable_action[0]))\n",
    "                action = (acceptable_action[0][random_idx], acceptable_action[1][random_idx])\n",
    "            else:\n",
    "                action = best_action\n",
    "                \n",
    "            # 遷移後状態を計算する（まだ遷移させない）。\n",
    "            next_state = transition(current_state, action)\n",
    "\n",
    "            # ゲームの終了判定\n",
    "            if reward==-1.:\n",
    "                winner = 1 - current_move\n",
    "                surrender = True\n",
    "            else:\n",
    "                winner = judge_game(next_state)\n",
    "                if winner is not None:\n",
    "                    surrender = True\n",
    "\n",
    "            # 報酬の計算\n",
    "#            if winner==current_move:\n",
    "#                reward = 1.\n",
    "#            else:\n",
    "#                reward = discount * my_value\n",
    "\n",
    "#            print(reward,surrender)\n",
    "            x_train.append(current_state)\n",
    "            y_train.append(np.expand_dims(reward,0))\n",
    "            if len(x_train)>32:\n",
    "                popidx = np.random.randint(0,33)\n",
    "                x_train.pop(popidx)\n",
    "                y_train.pop(popidx)\n",
    "                \n",
    "            # 状態価値の更新\n",
    "            value_function.fit(\n",
    "                x=np.array(x_train),\n",
    "                y=np.array(y_train),\n",
    "                epochs=1,\n",
    "                verbose=0,\n",
    "            )\n",
    "\n",
    "            if surrender:\n",
    "                raise Exception\n",
    "\n",
    "            # 状態を更新する。\n",
    "            current_state = copy.deepcopy(next_state)\n",
    "\n",
    "    except Exception as e:\n",
    "#        print('Game Over')\n",
    "#        print('type:' + str(type(e)))\n",
    "#        print('args:' + str(e.args))\n",
    "#        print('message:' + e.message)\n",
    "#        print('e自身:' + str(e))\n",
    "        pass\n",
    "\n",
    "    # 最終盤面の表示\n",
    "    if False:\n",
    "        show_state_2(current_state)\n",
    "        if winner is None:\n",
    "            plt.title('episode: '+str(nb_episode)+' draw'+'  nb_move='+str(nb_move+1))\n",
    "        else:\n",
    "            if winner==0:\n",
    "                winner_name='Red'\n",
    "            else:\n",
    "                winner_name='Blue'\n",
    "            plt.title('episode: '+str(nb_episode)+' '+winner_name+' won'+'  nb_move='+str(nb_move+1))\n",
    "        plt.show()\n",
    "\n",
    "    # epsilonを減衰させる。\n",
    "    epsilon = epsilon * 0.99    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1824b591d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 状態の初期化\n",
    "current_state = np.zeros((nb_mesh,nb_mesh,3))\n",
    "current_state[:,:,-1] = np.random.randint(0,2) # ランダムに先手を決める。\n",
    "\n",
    "# ランダムに初手を決める\n",
    "acceptable_action = get_permitted_actions(current_state)\n",
    "random_idx = np.random.randint(0,len(acceptable_action[0]))\n",
    "action = (acceptable_action[0][random_idx], acceptable_action[1][random_idx])\n",
    "current_state = transition(current_state, action)\n",
    "\n",
    "winner = None\n",
    "\n",
    "plt.figure(figsize=(5,4*nb_mesh*nb_mesh//2))\n",
    "\n",
    "try:\n",
    "    surrender = False\n",
    "    for nb_move in range(nb_mesh*nb_mesh):\n",
    "\n",
    "        # 盤面の表示\n",
    "        plt.subplot(nb_mesh*nb_mesh//2+1,2,nb_move+1)\n",
    "        show_state_2(current_state)\n",
    "\n",
    "        # 現在の指し手\n",
    "        current_move = current_state[0,0,-1].astype(np.int32)\n",
    "\n",
    "        # 状態価値が最も高くなる行動と、その行動を取った時の遷移後の状態価値を計算する。\n",
    "        my_value, best_action = search_best_action(current_state, value_function)\n",
    "\n",
    "        # 状態価値が最も高くなる行動を選択する。ただし、確率εでランダムな行動を取る。\n",
    "#        if np.random.random(1)<epsilon:\n",
    "#            acceptable_action = get_permitted_actions(current_state)\n",
    "#            random_idx = np.random.randint(0,len(acceptable_action[0]))\n",
    "#            action = (acceptable_action[0][random_idx], acceptable_action[1][random_idx])\n",
    "#        else:\n",
    "#            action = best_action\n",
    "        action = best_action\n",
    "\n",
    "        # 遷移後状態を計算する（まだ遷移させない）。\n",
    "        next_state = transition(current_state, action)\n",
    "\n",
    "        # ゲームの終了判定\n",
    "        if my_value==-1.:\n",
    "            winner = 1 - current_move\n",
    "#            surrender = True\n",
    "        else:\n",
    "            winner = judge_game(next_state)\n",
    "            if winner is not None:\n",
    "                surrender = True\n",
    "\n",
    "        if current_move==0:\n",
    "            score_red = my_value\n",
    "            score_blue = -my_value\n",
    "        else:\n",
    "            score_red = -my_value\n",
    "            score_blue = my_value\n",
    "            \n",
    "        if winner is None:\n",
    "            plt.title('Red:'+'{:.2f}'.format(score_red)+' Blue:'+'{:.2f}'.format(score_blue))\n",
    "        else:\n",
    "            if winner==0:\n",
    "                winner_name='Red'\n",
    "            else:\n",
    "                winner_name='Blue'\n",
    "            plt.title(winner_name+' won'+'  nb_move='+str(nb_move+1))\n",
    "            \n",
    "        # 状態を更新する。\n",
    "        current_state = copy.deepcopy(next_state)\n",
    "        \n",
    "        if surrender:\n",
    "            raise Exception\n",
    "\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 最終盤面の表示\n",
    "if True:\n",
    "    plt.subplot(nb_mesh*nb_mesh//2+1,2,nb_move+2)\n",
    "    show_state_2(current_state)\n",
    "\n",
    "    if winner is None:\n",
    "        plt.title(' draw'+'  nb_move='+str(nb_move+1))\n",
    "    else:\n",
    "        if winner==0:\n",
    "            winner_name='Red'\n",
    "        else:\n",
    "            winner_name='Blue'\n",
    "        plt.title(winner_name+' won'+'  nb_move='+str(nb_move+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl35]",
   "language": "python",
   "name": "conda-env-dl35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
